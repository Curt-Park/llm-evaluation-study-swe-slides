# EvoEval (Xia, Deng, Zhang, 2024)

**논문**: "EvoEval: Evolving Coding Benchmarks via LLM"
**저자**: Chunqiu Steven Xia, Yinlin Deng, Lingming Zhang
**발표**: COLM 2024
**arXiv**: 2403.19114

---

## 핵심 수치

| 항목 | 수치 |
|------|------|
| 원본 HumanEval 문제 수 | 164개 |
| 변형 방식 수 | **7가지** |
| 평가 LLM 수 | **51개** |
| 평균 성능 하락폭 | **39.4%** |
| 성능 하락 범위 | **19.6 ~ 47.7%p** |

---

## 7가지 변형 방식

1. **Difficult**: 문제를 더 어렵게 (엣지 케이스 추가, 조건 복잡화)
2. **Creative**: 새로운 도메인으로 유사 문제 생성
3. **Subtle**: 미묘한 의미 변화
4. **Combine**: 두 함수를 하나로 합침
5. **Tool Use**: 외부 도구·라이브러리 활용 요구
6. **Translate**: 입출력 형식 변환
7. **Remove Bugs**: 버그 있는 코드에서 디버깅

> ℹ️ 7가지 변형은 논문에서 확인된 수치.

---

## 핵심 발견

- Top 모델들이 HumanEval 원본에서 90%+ 달성하지만 변형 태스크에서 급락
- 평균 39.4% 하락 (51개 LLM 기준)
- 하락 범위: 19.6 ~ 47.7%p (변형 방식별, 모델별 편차)
- 표현만 바뀌었을 때 풀지 못함 → 패턴 암기에 의존

---

## 시사점

- HumanEval 포화의 일부는 진짜 능력 향상이 아닌 암기
- 변형 문제에 강건하지 않다 → 벤치마크 다양성의 필요성
- 모델의 진짜 이해 능력과 암기 능력을 구분하는 평가 설계가 중요
